{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# P1 - Navigation\n",
    "\n",
    "---\n",
    "\n",
    "You are welcome to use this coding environment to train your agent for the project.  Follow the instructions below to get started!\n",
    "\n",
    "### 1. Start the Environment\n",
    "\n",
    "Run the next code cell to install a few packages.  This line will take a few minutes to run!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchsummary\n",
      "  Downloading https://files.pythonhosted.org/packages/7d/18/1474d06f721b86e6a9b9d7392ad68bed711a02f3b61ac43f13c719db50a6/torchsummary-1.5.1-py3-none-any.whl\n",
      "Installing collected packages: torchsummary\n",
      "Successfully installed torchsummary-1.5.1\n"
     ]
    }
   ],
   "source": [
    "!pip -q install ./python\n",
    "!pip install torchsummary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The environment is already saved in the Workspace and can be accessed at the file path provided below.  Please run the next code cell without making any changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\t\n",
      "Unity brain name: BananaBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 37\n",
      "        Number of stacked Vector Observation: 1\n",
      "        Vector Action space type: discrete\n",
      "        Vector Action space size (per agent): 4\n",
      "        Vector Action descriptions: , , , \n"
     ]
    }
   ],
   "source": [
    "from unityagents import UnityEnvironment\n",
    "import numpy as np\n",
    "env = UnityEnvironment(file_name=\"/data/Banana_Linux_NoVis/Banana.x86_64\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Environments contain **_brains_** which are responsible for deciding the actions of their associated agents. Here we check for the first brain available, and set it as the default brain we will be controlling from Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the default brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Examine the State and Action Spaces\n",
    "\n",
    "(from https://github.com/udacity/deep-reinforcement-learning/tree/master/p1_navigation)\n",
    "\n",
    "This project trains an agent to navigate (and collect bananas) in a large, square world.\n",
    "\n",
    "A reward of +1 is provided for collecting a yellow banana, and a reward of -1 is provided for collecting a blue banana. Thus, the goal of your agent is to collect as many yellow bananas as possible while avoiding blue bananas.\n",
    "\n",
    "The state space has 37 dimensions and contains the agent's velocity, along with ray-based perception of objects around agent's forward direction. Given this information, the agent has to learn how to best select actions. Four discrete actions are available, corresponding to:\n",
    "\n",
    "+ 0 - move forward.\n",
    "\n",
    "+ 1 - move backward.\n",
    "\n",
    "+ 2 - turn left.\n",
    "\n",
    "+ 3 - turn right.\n",
    "\n",
    "The task is episodic, and in order to solve the environment, the agent must get an average score of +13 over 100 consecutive episodes.\n",
    "\n",
    "<br>\n",
    "<center>\n",
    "<img src=\"https://user-images.githubusercontent.com/10624937/42135619-d90f2f28-7d12-11e8-8823-82b970a54d7e.gif\">\n",
    "</center>\n",
    "<br>\n",
    "\n",
    "Run the code cell below to print some information about the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of agents: 1\n",
      "Number of actions: 4\n",
      "States have length: 37\n"
     ]
    }
   ],
   "source": [
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "print('Number of agents:', len(env_info.agents))\n",
    "action_size = brain.vector_action_space_size\n",
    "print('Number of actions:', action_size)\n",
    "state = env_info.vector_observations[0]\n",
    "# print('States look like:', state)\n",
    "print('States have length:', len(state))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Take Random Actions in the Environment\n",
    "\n",
    "In the next code cell, you will learn how to use the Python API to control the agent and receive feedback from the environment.\n",
    "\n",
    "Note that **in this coding environment, you will not be able to watch the agent while it is training**, and you should set `train_mode=True` to restart the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.0\n"
     ]
    }
   ],
   "source": [
    "env_info = env.reset(train_mode=True)[brain_name] # reset the environment\n",
    "state = env_info.vector_observations[0]            # get the current state\n",
    "score = 0                                          # initialize the score\n",
    "while True:\n",
    "    action = np.random.randint(action_size)        # select an action\n",
    "    env_info = env.step(action)[brain_name]        # send the action to the environment\n",
    "    next_state = env_info.vector_observations[0]   # get the next state\n",
    "    reward = env_info.rewards[0]                   # get the reward\n",
    "    done = env_info.local_done[0]                  # see if episode has finished\n",
    "    score += reward                                # update the score\n",
    "    state = next_state                             # roll over the state to next time step\n",
    "    if done:                                       # exit loop if episode finished\n",
    "        break\n",
    "    \n",
    "print(\"Score: {}\".format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When finished, you can close the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"blue\"><h1>Implementation</h1></font>\n",
    "<hr>\n",
    "\n",
    "The implementation is largely based on the 'LunarLander-v2' example given in Lesson 2: Deep Q-Networks.\n",
    "The main adaptation was using a Unity environment instead of the OpenAI Gym environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "We will use a Deep Neural Network as the function approximator for the Q function. The chosen DNN architecture is a 3 layer fully connected neural network with the input layer dimension being 37, the first hidden layer being 64 dimensional, the second hidden layer also being 64 dimensional, and the final output layer being 4 dimensional (for each different action). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class QNetwork(nn.Module):\n",
    "    \"\"\"Actor (Policy) Model.\"\"\"\n",
    "\n",
    "    def __init__(self, state_size, action_size, seed, fc1_units=64, fc2_units=64):\n",
    "        \"\"\"\n",
    "        state_size (int): Dimension of each state\n",
    "        action_size (int): Dimension of each action\n",
    "        seed (int): Random seed\n",
    "        \"\"\"\n",
    "\n",
    "        super(QNetwork, self).__init__()\n",
    "        self.seed = torch.manual_seed(seed)\n",
    "\n",
    "        self.fc1 = nn.Linear(state_size, fc1_units)\n",
    "        self.fc2 = nn.Linear(fc1_units, fc2_units)\n",
    "        self.fc3 = nn.Linear(fc2_units, action_size)\n",
    "        \n",
    "\n",
    "    def forward(self, state):\n",
    "        \"\"\"Build a network that maps state -> action values.\"\"\"\n",
    "        \n",
    "        x = F.relu(self.fc1(state))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return self.fc3(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1                   [-1, 64]           2,432\n",
      "            Linear-2                   [-1, 64]           4,160\n",
      "            Linear-3                    [-1, 4]             260\n",
      "================================================================\n",
      "Total params: 6,852\n",
      "Trainable params: 6,852\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.00\n",
      "Params size (MB): 0.03\n",
      "Estimated Total Size (MB): 0.03\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "model = QNetwork(37, 4, 0)\n",
    "summary(model, input_size=(37,-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent\n",
    "\n",
    "The model will be trained using Gradient Descent with the **Adam optimizer** to update the weights.\n",
    "\n",
    "Nonlinear function approximators like neural networks can run into instabilities. To help improve convergence, two modifications will be made:\n",
    "\n",
    "+  **Experience Replay** -  To avoid learning experiences in sequence (which will lead to correlations between them) we store all the experience tuples (state, action, reward, and next state) in a memory buffer. The agent will learn from randomly sampled experiences from this buffer. This also helps us learn from the same experience multiple times, which is especially useful when encountering rare experiences. \n",
    "\n",
    "+ **Fixed Q-values** - The TD target is also dependent on the network parameter w that we are trying to learn/update, and this can lead to instabilities. To address it, a separate network with identical architecture but different weights is used. \n",
    "The target network gets updated slowly according to the hyperparameter TAU while the local network aggressively “learns” with each update. At a high level, this loss function is taking the squared error between a conservative/stable estimate of the value of state 𝑠 and action 𝑎 (the actual reward received plus the discounted value from the more stable target model) and the more aggressive guess of that value prior to taking action 𝑎.\n",
    "\n",
    "The learning algorithm uses an **Epislon Greedy algorithm** to select actions while being trained. The epsilon represents the probability of choosing an action at random instead of following what is currently expected to be the “best” action in the given state (exploration vs. exploitation). \n",
    "\n",
    "The Agent class defines how an agent acts when asked to provide an action, learn from a time step, update the target network and manages the memory buffer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from collections import namedtuple, deque\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "BUFFER_SIZE = int(1e5)  # replay buffer size\n",
    "BATCH_SIZE = 64         # minibatch size\n",
    "GAMMA = 0.99            # discount factor\n",
    "TAU = 1e-3              # for soft update of target parameters\n",
    "LR = 5e-4               # learning rate \n",
    "UPDATE_EVERY = 4        # how often to update the network\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class Agent():\n",
    "    \"\"\"Interacts with and learns from the environment.\"\"\"\n",
    "\n",
    "    def __init__(self, state_size, action_size, seed):\n",
    "        \"\"\"Initialize an Agent object.\n",
    "        \n",
    "        Params\n",
    "        ======\n",
    "            state_size (int): dimension of each state\n",
    "            action_size (int): dimension of each action\n",
    "            seed (int): random seed\n",
    "        \"\"\"\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.seed = random.seed(seed)\n",
    "\n",
    "        # Q-Network\n",
    "        self.qnetwork_local = QNetwork(state_size, action_size, seed).to(device)\n",
    "        self.qnetwork_target = QNetwork(state_size, action_size, seed).to(device)\n",
    "        self.optimizer = optim.Adam(self.qnetwork_local.parameters(), lr=LR)\n",
    "\n",
    "        # Replay memory\n",
    "        self.memory = ReplayBuffer(action_size, BUFFER_SIZE, BATCH_SIZE, seed)\n",
    "        # Initialize time step (for updating every UPDATE_EVERY steps)\n",
    "        self.t_step = 0\n",
    "    \n",
    "    def step(self, state, action, reward, next_state, done):\n",
    "        # Save experience in replay memory\n",
    "        self.memory.add(state, action, reward, next_state, done)\n",
    "        \n",
    "        # Learn every UPDATE_EVERY time steps.\n",
    "        self.t_step = (self.t_step + 1) % UPDATE_EVERY\n",
    "        if self.t_step == 0:\n",
    "            # If enough samples are available in memory, get random subset and learn\n",
    "            if len(self.memory) > BATCH_SIZE:\n",
    "                experiences = self.memory.sample()\n",
    "                self.learn(experiences, GAMMA)\n",
    "\n",
    "    def act(self, state, eps=0.):\n",
    "        \"\"\"Returns actions for given state as per current policy.\n",
    "        \n",
    "        Params\n",
    "        ======\n",
    "            state (array_like): current state\n",
    "            eps (float): epsilon, for epsilon-greedy action selection\n",
    "        \"\"\"\n",
    "        \n",
    "        # Get Q action values from state\n",
    "        state = torch.from_numpy(state).float().unsqueeze(0).to(device)\n",
    "        self.qnetwork_local.eval()\n",
    "        with torch.no_grad():\n",
    "            action_values = self.qnetwork_local(state)\n",
    "        self.qnetwork_local.train()\n",
    "\n",
    "        # Epsilon-greedy action selection\n",
    "        if random.random() > eps:\n",
    "            return np.argmax(action_values.cpu().data.numpy())\n",
    "        else:\n",
    "            return random.choice(np.arange(self.action_size))\n",
    "\n",
    "    def learn(self, experiences, gamma):\n",
    "        \"\"\"Update value parameters using given batch of experience tuples.\n",
    "\n",
    "        Params\n",
    "        ======\n",
    "            experiences (Tuple[torch.Variable]): tuple of (s, a, r, s', done) tuples \n",
    "            gamma (float): discount factor\n",
    "        \"\"\"\n",
    "        states, actions, rewards, next_states, dones = experiences\n",
    "        \n",
    "        # Get max predicted Q-values (for next state) from target model\n",
    "        Q_targets_next = self.qnetwork_target(next_states).detach().max(1)[0].unsqueeze(1)\n",
    "        \n",
    "        # Compute Q targets from current model\n",
    "        Q_targets = rewards + (gamma * Q_targets_next * (1- dones))\n",
    "        \n",
    "        # Get expected Q values from local model\n",
    "        Q_expected = self.qnetwork_local(states).gather(1, actions)\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = F.mse_loss(Q_expected, Q_targets)\n",
    "        \n",
    "        # Minimize loss\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "        # ------------------- update target network ------------------- #\n",
    "        self.soft_update(self.qnetwork_local, self.qnetwork_target, TAU)                     \n",
    "\n",
    "    def soft_update(self, local_model, target_model, tau):\n",
    "        \"\"\"Soft update model parameters.\n",
    "        θ_target = τ*θ_local + (1 - τ)*θ_target\n",
    "\n",
    "        Params\n",
    "        ======\n",
    "            local_model (PyTorch model): weights will be copied from\n",
    "            target_model (PyTorch model): weights will be copied to\n",
    "            tau (float): interpolation parameter \n",
    "        \"\"\"\n",
    "        for target_param, local_param in zip(target_model.parameters(), local_model.parameters()):\n",
    "            target_param.data.copy_(tau*local_param.data + (1.0-tau)*target_param.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use Experience Replay we define a memory buffer class. An object of ReplayBuffer initializes a deque to store the experience tuples. It has methods to store a new experience tuple and to return a sample of experiences of a given batch_size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayBuffer:\n",
    "    \"\"\"Fixed-size buffer to store experience tuples.\"\"\"\n",
    "\n",
    "    def __init__(self, action_size, buffer_size, batch_size, seed):\n",
    "        \"\"\"Initialize a ReplayBuffer object.\n",
    "\n",
    "        Params\n",
    "        ======\n",
    "            action_size (int): dimension of each action\n",
    "            buffer_size (int): maximum size of buffer\n",
    "            batch_size (int): size of each training batch\n",
    "            seed (int): random seed\n",
    "        \"\"\"\n",
    "        self.action_size = action_size\n",
    "        self.memory = deque(maxlen=buffer_size)  \n",
    "        self.batch_size = batch_size\n",
    "        self.experience = namedtuple(\"Experience\", field_names=[\"state\", \"action\", \"reward\", \"next_state\", \"done\"])\n",
    "        self.seed = random.seed(seed)\n",
    "    \n",
    "    def add(self, state, action, reward, next_state, done):\n",
    "        \"\"\"Add a new experience to memory.\"\"\"\n",
    "        e = self.experience(state, action, reward, next_state, done)\n",
    "        self.memory.append(e)\n",
    "    \n",
    "    def sample(self):\n",
    "        \"\"\"Randomly sample a batch of experiences from memory.\"\"\"\n",
    "        experiences = random.sample(self.memory, k=self.batch_size)\n",
    "\n",
    "        states = torch.from_numpy(np.vstack([e.state for e in experiences if e is not None])).float().to(device)\n",
    "        actions = torch.from_numpy(np.vstack([e.action for e in experiences if e is not None])).long().to(device)\n",
    "        rewards = torch.from_numpy(np.vstack([e.reward for e in experiences if e is not None])).float().to(device)\n",
    "        next_states = torch.from_numpy(np.vstack([e.next_state for e in experiences if e is not None])).float().to(device)\n",
    "        dones = torch.from_numpy(np.vstack([e.done for e in experiences if e is not None]).astype(np.uint8)).float().to(device)\n",
    "  \n",
    "        return (states, actions, rewards, next_states, dones)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Return the current size of internal memory.\"\"\"\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainig the DQN\n",
    "\n",
    "The following code corresponds to the DQN algorithm.\n",
    "It returns the list of scores for all episodes and terminates when a value >= 13.0 of the average score over the last 100 episodes is achieved.\n",
    "\n",
    "Epsilon decays from a starting value eps_start=1.0 until it reaches a minimal value of eps_end=0.001 with eps_decay=0.995."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def dqn(n_episodes=2000, max_t=1000, eps_start=1.0, eps_end=0.01, eps_decay=0.995):\n",
    "    \"\"\"Deep Q-Learning.\n",
    "    \n",
    "    Params\n",
    "    ======\n",
    "        n_episodes (int): maximum number of training episodes\n",
    "        max_t (int): maximum number of timesteps per episode\n",
    "        eps_start (float): starting value of epsilon, for epsilon-greedy action selection\n",
    "        eps_end (float): minimum value of epsilon\n",
    "        eps_decay (float): multiplicative factor (per episode) for decreasing epsilon\n",
    "    \"\"\"\n",
    "    scores = []                        # list containing scores from each episode\n",
    "    scores_window = deque(maxlen=100)  # last 100 scores\n",
    "    eps = eps_start                    # initialize epsilon\n",
    "    for i_episode in range(1, n_episodes+1):\n",
    "\n",
    "        env_info = env.reset(train_mode=True)[brain_name] # reset the environment\n",
    "        state = env_info.vector_observations[0] \n",
    "        score = 0\n",
    "        \n",
    "        \n",
    "        for t in range(max_t):\n",
    "            \n",
    "            action = agent.act(state, eps)                 # select an action\n",
    "            env_info = env.step(action)[brain_name]        # send the action to the environment\n",
    "            next_state = env_info.vector_observations[0]   # get the next state\n",
    "            reward = env_info.rewards[0]                   # get the reward\n",
    "            done = env_info.local_done[0]                  # see if episode has finished\n",
    "            \n",
    "            agent.step(state, action, reward, next_state, done)\n",
    "            \n",
    "            state = next_state\n",
    "            score += reward\n",
    "            if done:\n",
    "                break \n",
    "                \n",
    "\n",
    "        scores_window.append(score)       # save most recent score\n",
    "        scores.append(score)              # save most recent score\n",
    "        eps = max(eps_end, eps_decay*eps) # decrease epsilon\n",
    "        \n",
    "        print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(i_episode, np.mean(scores_window)), end=\"\")\n",
    "        if i_episode % 100 == 0:\n",
    "            print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(i_episode, np.mean(scores_window)))\n",
    "        if np.mean(scores_window)>=13.0:\n",
    "            print('\\nEnvironment solved in {:d} episodes!\\tAverage Score: {:.2f}'.format(i_episode-100, np.mean(scores_window)))\n",
    "            torch.save(agent.qnetwork_local.state_dict(), 'checkpoint.pth')\n",
    "            break\n",
    "    return scores\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Agent\n",
    "\n",
    "The following code initializes an Agent object and runs the DQN algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 100\tAverage Score: 1.26\n",
      "Episode 200\tAverage Score: 4.45\n",
      "Episode 300\tAverage Score: 7.81\n",
      "Episode 400\tAverage Score: 10.92\n",
      "Episode 500\tAverage Score: 12.38\n",
      "Episode 533\tAverage Score: 13.06\n",
      "Environment solved in 433 episodes!\tAverage Score: 13.06\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f95c7c6bf98>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initiate Agent\n",
    "agent = Agent(state_size=37, action_size=4, seed=0)\n",
    "\n",
    "# Train Agent and get scores\n",
    "scores = dqn()\n",
    "\n",
    "# Close Environment\n",
    "# env.close()\n",
    "\n",
    "# Plot the scores\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(np.arange(len(scores)), scores)\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Episode #')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"blue\">\n",
    "An average score > 13.0 over the last 100 episodes was achieved at <b>433</b> episodes.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test loaded model\n",
    "\n",
    "The weights of the trained model are saved in 'checkpoint.pth'.\n",
    "We can use these weights to test our trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 14.0\n"
     ]
    }
   ],
   "source": [
    "# Initiate Agent\n",
    "agent = Agent(state_size=37, action_size=4, seed=0)\n",
    "\n",
    "# load the weights from file\n",
    "agent.qnetwork_local.load_state_dict(torch.load('checkpoint.pth'))\n",
    "\n",
    "            \n",
    "env_info = env.reset(train_mode=True)[brain_name] # reset the environment\n",
    "state = env_info.vector_observations[0]            # get the current state\n",
    "score = 0                                          # initialize the score\n",
    "while True:\n",
    "    action = agent.act(state)                      # select an action\n",
    "    env_info = env.step(action)[brain_name]        # send the action to the environment\n",
    "    next_state = env_info.vector_observations[0]   # get the next state\n",
    "    reward = env_info.rewards[0]                   # get the reward\n",
    "    done = env_info.local_done[0]                  # see if episode has finished\n",
    "    score += reward                                # update the score\n",
    "    state = next_state                             # roll over the state to next time step\n",
    "    if done:                                       # exit loop if episode finished\n",
    "        break\n",
    "    \n",
    "print(\"Score: {}\".format(score))\n",
    "            \n",
    "# env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
